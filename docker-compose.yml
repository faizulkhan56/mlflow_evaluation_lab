version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: mlflow-postgres
    environment:
      POSTGRES_USER: mlflow
      POSTGRES_PASSWORD: mlflow
      POSTGRES_DB: mlflow
    volumes:
      - postgres-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U mlflow"]
      interval: 5s
      timeout: 5s
      retries: 5

  # MLflow Tracking Server
  mlflow-server:
    build:
      context: .
      dockerfile: Dockerfile.mlflow-server
    container_name: mlflow-server
    ports:
      - "5000:5000"
    volumes:
      - mlflow-artifacts:/app/mlruns
    working_dir: /app
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=mlflow
      - POSTGRES_PASSWORD=mlflow
      - POSTGRES_DB=mlflow
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:5000/health"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s

  # Python application container for running evaluation scripts
  mlflow-app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: mlflow-app
    depends_on:
      mlflow-server:
        condition: service_healthy
    volumes:
      - mlflow-artifacts:/app/mlruns
      - .:/app
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow-server:5000
      - MLFLOW_REGISTRY_URI=http://mlflow-server:5000
      # Kaggle API credentials for downloading datasets (from .env file)
      - KAGGLE_USERNAME=${KAGGLE_USERNAME}
      - KAGGLE_KEY=${KAGGLE_KEY}
    # Override command to keep container running
    # Users can exec into container to run scripts manually
    # Remove this line if you want classification.py to run automatically on startup
    command: tail -f /dev/null

  # FastAPI Prediction API Server
  mlflow-api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: mlflow-api
    ports:
      - "8000:8000"
    depends_on:
      mlflow-server:
        condition: service_healthy
    volumes:
      - mlflow-artifacts:/app/mlruns
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow-server:5000
      - MLFLOW_REGISTRY_URI=http://mlflow-server:5000
      - GIT_PYTHON_REFRESH=quiet
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 600s  # Allow 10 minutes for model loading

# Named volumes for data persistence
volumes:
  postgres-data:
    driver: local
  mlflow-artifacts:
    driver: local

